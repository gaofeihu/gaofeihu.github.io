---
layout:     post
title:  docker进阶
subtitle: docker进阶
date:       2020-1-29
author:     silence
header-img: img/post-linux.png
catalog: true
tags:
    - linux
    - docker
---

### 1. docker网络管理

#### 1.1docker中的网络通讯

> 在通常情况下，Docker 使用网桥( Bridge )与 NAT 的通信模式 

##### (1) 容器访问外部网络

 ```bash
iptables -t nat -A POSTROUTING -s 172.17.0.0/16 -o docker0 -j MASQUERADE 
 ```

##### (2) 外部网络访问容器 

```bash
docker run -d -p 80:80 apache
iptables -t nat -A  PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
iptables -t nat -A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j  DNAT --to-destination 172.17.0.2:80
```

#### 1.2 Docker 进程网络修改 

```bash
-b, --bridge=”” 
# 指定 Docker 使用的网桥设备，默认情况下 Docker 会自动创建和使用 docker0 网桥设备，通过此 参数可以使用已经存在的设备
--bip 
# 指定 Docker0 的 IP 和掩码，使用标准的 CIDR 形式，如 10.10.10.10/24 
--dns 
#配置容器的 DNS，在启动 Docker 进程是添加，所有容器全部生效
```

#### 1.3 docker容器网路修改

```
--dns 用于指定启动的容器的 DNS

--net 用于指定容器的网络通讯方式，有以下四个值
	➢bridge:Docker 默认方式，网桥模式
	➢none:容器没有网络栈
	➢container:使用其它容器的网络栈，Docker容器会加入其它容器的 network namespace 
	➢host:表示容器使用 Host 的网络，没有自己独立的网络栈。容器可以完全访问 Host 的网络，不安全
```

#### 1.4 暴露端口

```bash
-p / P 选项的使用格式
> -p :<ContainerPort> 将制定的容器端口映射至主机所有地址的一个动态端口 > -p <HostPort>:<ContainerPort>:映射至指定的主机端口
> -p <IP>::<ContainerPort>:映射至指定的主机的 IP 的动态端口
> -p <IP>:<HostPort>:<ContainerPort>:映射至指定的主机 IP 的主机端口
> -P(大):暴露所需要的所有端口
```

docker port ContainerName 可以查看容器当前的映射关系 

#### 1.5 自定义 Docker0 网桥的网络地址 

```bash
# 修改 /etc/docker/daemon.json 文件
{
"bip": "192.168.1.5/24",
"fixed-cidr": "10.20.0.0/16", "fixed-cidr-v6": "2001:db8::/64",
"mtu": "1500",
"default-gateway": "10.20.1.1", "default-gateway-v6": "2001:db8:abcd::89", "dns": ["10.20.1.2","10.20.1.3"]
}
```

### 2. 常见隔离方式

```bash
docker network ls 查看当前可用的网络类型 

docker network create -d 类型 网络空间名称 
```

类型分为:

- overlay network #  不同的主机之间可以互相通讯 需要借助第三方软件
- bridge network

```
# 创建网络空间并使用
docker network create -d bridge mynet

docker run -d -p 80:80 --net=mynet 2dc68ff797db

```



#### **2.1namespace**

| **namespace** | **系统调用参数** | **隔离内容**               | **内核版本** |
| ------------- | ---------------- | -------------------------- | ------------ |
| UTS           | CLONE_NEWUTS     | 主机名和域名               | 2.6.19       |
| IPC           | CLONE_NEWIPC     | 信号量、消息队列和共享内存 | 2.6.19       |
| PID           | CLONE_NEWPID     | 进程编号                   | 2.6.24       |
| NetWork       | CLONE_NEWNET     | 网络设备、网络栈、端口等   | 2.6.29       |
| Mount         | CLONE_NEWNS      | 挂载点（文件系统）         | 2.4.19       |
| User          | CLONE_NEWUSER    | 用户和用户组               | 3.8          |

#### 2.2 不同网络之间进行隔离

```bash
docker network create -d bridge --subnet "172.26.0.0/16" --gateway "172.26.0.1" my-bridge-network
docker run -d --network=my-bridge-network --name test1  hub.c.163.com/public/centos:6.7-tools
docker run -d --name test2  hub.c.163.com/public/centos:6.7-tools
```

#### 2.3 Linux 桥接器进行主机间通讯 - 1 

创建网桥

```bash
vi ifcfg-eth0
  DEVICE=eth0
  HWADDR=00:0C:29:06:A2:35
  TYPE=Ethernet
  UUID=34b706cc-aa46-4be3-91fc-d1f48c301f23
  ONBOOT=yes
  BRIDGE=br0
  NM_CONTROLLED=yes
  BOOTPROTO=static
vi ifcfg-br0 //改成这样
DEVICE=br0
TYPE=Bridge
ONBOOT=yes 
BOOTPROTO=static 
IPADDR=192.168.216.131 
NETMASK=255.255.255.0 
GATEWAY=192.168.216.2 
DNS=8.8.8.8
```

#### Linux 桥接器进行主机间通讯 - 2 

```bash
[root@localhost network-scripts]# yum install -y git
[root@localhost network-scripts]# git clone https://github.com/jpetazzo/pipework [root@localhost network-scripts]# cp pipework/pipework /usr/local/bin/
[root@localhost network-scripts]# docker run --name nginx -d --net=none 2dc68ff797db
[root@localhost network-scripts]# pipework br0 nginx 10.10.10.16/24
```

### 

***



### 2.  数据存储

#### 2.1数据卷特性 

-  Docker 镜像由多个只读层叠加而成，启动容器时，Docker 会加载只读镜像层并在镜像栈顶部添加一个读写层 

-  如果运行中的容器修改了现有的一个已经存在的文件，那么该文件将会从读写层下面的的只读层复制到读写层，该文件的只读版本仍然存在，只是已经被读写层中该文件的副本所隐藏，次即“写时复制”机制 

#### 2.2 数据卷意义 

- 关闭并重启容器，其数据不受影响;但删除 Docker 容器，则其改变将会全部丢失 
- 存在的问题
  - 存在于联合文件系统中， 不易于宿主机访问
  - 容器间数据共享不便
  - 删除容器其数据会丢失 	
- 解决方案:“卷”
  - “卷”是容器上的一个或多个“目录” ，此类目录可绕过联合文件系统，与宿主机上的某目录“绑定” 
- Volume 可以在运行容器时即完成创建与绑定操作。当然，前提需要拥有对应的申明 
-  Volume 的初衷就是数据持久化 

#### 2.3 数据卷类型

```
> Bind mount volume
> Docker-managed volume
```

#### 2.4 在容器中使用 Volumes 

- Docker-managed Volume
    ```
    - docker run -it --name roc -v MOUNTDIR roc/lamp:v1.0
    - docker inspect -f {{.Mounts}}  roc
    ```
    
    
    
- Bind-mount Volume
   ```bash
   # 优先级大于自动管理卷
   docker run -it --name roc -v HOSTDIR:VOLUMEDIR roc/lamp:v1.0
   ```

   

- Union Volume
  
   ```
   docker run -it --name roc --volumes-from ContainerName roc/lamp:v1.0
   ```
   
   

`挂载资源位置`

> /var/lib/docker/volumes

```bash
# 删除本地挂载
docker rm -f -v cid 
```



#### 2.5.存储驱动

Docker 存储驱动 ( storage driver ) 是 Docker 的核心组件，它是 Docker 实现分成镜像的基础 

1、device mapper ( DM ):性能和稳定性存在问题，不推荐生产环境使用 

2、btrfs:社区实现了 btrfs driver，稳定性和性能存在问题 

3、overlayfs:内核 3.18 overlayfs 进入主线，性能和稳定性优异，第一选择 



```
mount -t overlay overlay -olowerdir=./low,upperdir=./upper,workdir=./work ./merged
```

##### 修改为 overlayfs 存储驱动 

```bash
echo "overlay" > /etc/modules-load.d/overlay.conf
cat /proc/modules|grep overlay
reboot
vim /etc/systemd/system/docker.service
            --storage-driver=overlay \
```



### 3.**资源限制**  

>  CGroup 是 Control Groups 的缩写，是 Linux 内核提供的一种可以限制、记录、隔离进程组 (process groups) 所 使用的物力资源 (如 cpu memory i/o 等等) 的机制。2007 年进入 Linux 2.6.24 内核，CGroups 不是全新创造的，它 将进程管理从 cpuset 中剥离出来，作者是 Google 的 Paul Menage 
>
> 默认情况下，如果不对容器做任何限制，容器能够占用当前系统能给容器提供的所有资源 
>
>  Docker 限制可以从 Memory、CPU、Block I/O 三个方面 
>
>  OOME:Out Of Memory Exception
>  	一旦发生 OOME，任何进程都有可能被杀死，包括 docker daemon 在内 
>
>  	为此，Docker 调整了 docker daemon 的 OOM 优先级，以免被内核关闭 



#### 3.1 内存资源限制

- 为应用做内存压力测试，理解正常业务需求下使用的内存情况，然后才能进入生产环境使用
-  一定要限制容器的内存使用上限
- 尽量保证主机的资源充足，一旦通过监控发现资源不足，就进行扩容或者对容器进行迁移
- 如果可以(内存资源充足的情况)，尽量不要使用 swap，swap 的使用会导致内存计算复杂，对调度器非常不友好 

##### 内存参数

> 在 docker 启动参数中，和内存限制有关的包括(参数的值一般是内存大小，也就是一个正数，后面跟 着内存单位 b、k、m、g，分别对应 bytes、KB、MB、和 GB): 

```bash
# 容器能使用的最大内存大小，最小值为 4m
-m --memory
# 容器能够使用的 swap 大小
--memory-swap
# 默认情况下，主机可以把容器使用的匿名页(anonymous page)swap 出来，你可以设置一个 0-100 之间的值，代表允许 swap 出来的比例,一般不设置。
--memory-swappiness
# 设置一个内存使用的 soft limit,设置值小于 –m 设置
--memory-reservation
# 容器能够使用的 kernel memory 大小，最小值为 4m。
--kernel-memory
# 是否运行 OOM 的时候杀死容器。只有设置了 -m，才可以把这个选项设置为 false，否则容器会耗尽主机内存，而且导致主机应用被杀死
--oom-kill-disable
```



#### 3.2 CPU资源限制

> Docker 提供的 CPU 资源限制选项可以在多核系统上限制容器能利用哪些 vCPU。而对容器最多能使用的 CPU 时间 **有两种限制方式:** 
>
> • 一是有多个 CPU 密集型的容器竞争 CPU 时，设置各个容器能使用的 CPU 时间相对比例 
>
> • 二是以绝对的方式设置容器在每个调度周期内最多能使用的 CPU 时间 

```bash
# 允许使用的 CPU 集，值可以为 0-3,0,1 
--cpuset-cpus=""
# CPU 共享权值(相对权重)，默认值 1024
-c,--cpu-shares=0
# 允许在上执行的内存节点(MEMs)
--cpuset-mems=""
# 即可设置调度周期，CFS 周期的有效范围是 1ms~1s，对应的--cpu-period的数值范围是 1000~1000000
--cpu-period=0
# 设置在每个周期内容器能使用的 CPU 时间，容器的 CPU 配额必须不小于 1ms，即-- cpu-quota的值必须 >= 1000，单位微秒
--cpu-quota=0
# 能够限制容器可以使用的主机 CPU 个数，并且还可以指定如 1.5 之类的小数
--cpus 

docker run -it --cpu-period=50000 --cpu-quota=25000 ubuntu:16.04 /bin/bash
docker run -it --cpu-period=10000 --cpu-quota=20000 ubuntu:16.04 /bin/bash
```

NUMA 非统一内存访问(NUMA)是一种用于多处理器的电脑记忆体设计，内存访问时间取决于处理器的内存位置。 在NUMA 下，处理器访问它自己的本地存储器的速度比非本地存储器(存储器的地方到另一个处理器之间共享的处理器或存 储器)快一些 

##### 限制实验 

```bash
docker run --name stress -it --rm -m 256m lorel/docker-stress-ng:latest stress -vm 2
docker run --name stress -it --rm --cpus 2 lorel/docker-stress-ng:latest stress --cpu 8
docker run --name stress -it --rm --cpuset-cpus 0 lorel/docker-stress-ng:latest stress --cpu 8

# 查看docker运行状态
docker stats cid/cname
```

