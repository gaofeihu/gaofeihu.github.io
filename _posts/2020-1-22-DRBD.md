---
layout:     post
title:  drbd高可用服务（实现数据同步）
subtitle: drbd高可用服务（实现数据同步）
date:       2020-1-22
author:     silence
header-img: img/post-linux.png
catalog: true
tags:
    - linux
    - DRBD
---

### 1、基本介绍

#### DRBD（distrbuted replicated block device）：分布式复制块设备

类似 rsync + inotify 的架构：inotify基于文件系统上层，当文件系统中有数据发生变化，就调用rsync服务，将文件系统中的文件同步到备库。

#### **涉及对象**

drbd 中的块设备可以是磁盘分区，lvm逻辑卷，或整块磁盘等。

原理
drbd软件工作位置是在文件系统层级以下，比文件系统更加靠近操作系统内核及IO栈。

基于网络的raid-1，当我们将数据写入本地磁盘系统时，数据还会被实时发送到网络中另一台主机中，以相同的形式记录在另一个磁盘系统中，使得本地（主节点）与远程主机（备节点）的数据保持实时数据同步。

如果本地系统出现故障，那么远程主机上还会保留有一份和主节点相同的数据备份可以继续使用。不会数据不会丢失。还会提升访问数据的用户访问体验（直接接管提供服务，降低宕机修复时间）。drbd服务的作用类似于磁盘阵形里的raid1功能，就相当于把网络中的两台服务器做成了类似磁盘阵列里的raid1一样。


#### 两种工作模式

##### 1）实时同步模式（此种模式是生产环境中最常用的模式）：

当数据写到本地磁盘和远端服务器磁盘都成功后才会返回成功写入。DRBD服务协议C级别就是这种模式，可以防止本地和远端数据丢失和不一致。

##### 2）异步同步模式：

当数据写入到本地服务器成功后就返回成功写入，不管远端服务器是否写入成功。

还可能是数据写入到本地服务器或远端服的buffer成功后，返回成功，就是DRBD服务协议的A，B级别

提示：在nfs网络文件系统的时候也有类似的参数和功能。例如：nfs服务参数sync和async，mount挂载参数也有sync和async。


#### DRBD的3种同步复制协议

协议A：异步复制协议。本地写成功后立即返回，数据放在发送BUFFER中，可能丢失。

协议B：内存同步（半同步）复制协议。本地写成功并将数据发送到对方后立即返回，如果双机掉电，数据可能丢失（mysql5.5以上支持）。

协议C：同步复制协议。本地和对方服务器磁盘都写成功确认后返回成功。如果单机掉电后单机磁盘损坏，数据都不会丢失。

工作中一般用协议C。选择协议将影响流量，从而影响网络延时。


#### DRBD的生产应用模式

单主模式及主备模式，为典型的高可用性集群方案。

复主模式：需要采用共享cluster文件系统，如gfs和ocfs2。用于需要从2个节点并发访问数据的场合，需要特别配置。

#### 应用场景

生产场景中会有很多基于高可用服务器对drbd的数据同步解决方案。

例如：heartbeat+drbd+nfs/mfs/gfs，heartbeat+drbd+mysql/oracle等。实际上drbd可以配合任意需要数据同步的所有服务的应用场景。

#### 相关数据同步工具介绍

1) Rsync（sersync,inotify,lsyncd）

2) Scp

3) Nc

4) Nfs

5) Union双机同步

6) Csync2多机同步

7) 软件自身同步机制（mysql,oracle,mongdb,ttserver,redis...）

8) DRBD



***



### 构建

#### 1. 构建前的准备

- CentOS 6.x系统要升级到最新的内核才支持

- 两台机器时间同步

- 修改主机名与hosts文件

  ```
  # vim /etc/sysconfig/network
  hostname mfs-master
  hostname mfs-slave
  
  vim /etc/hosts
  10.10.10.17 mfs-master
  10.10.10.18 mfs-slave
  ```

  

#### 依赖安装

```bash
yum -y install gcc flex libxslt-devel libxslt perl
yum -y install kernel kernel-devel kernel-headers
# 也可以
yum -y install gcc gcc-c++ make glibc flex kernel-devel kernel-headers
```

#### 安装DRBD内核驱动程序

而红帽6是2.6.32的内核,最好使用第三方的RPM包

下载地址 https://www.linbit.com/en/drbd-community/drbd-download/

```bash
tar xf drbd-9.0.1-1.tar.gz 
cd drbd-9.0.1-1
make KDIR=/usr/src/kernels/2.6.32-642.el6.x86_64/
make install
# 加载DRBD模块:
modprobe drbd
# 查看DRBD模块是否加载到内核：
lsmod |grep drbd
```

#### 安装DRBD-util用户空间程序

下载地址 https://www.linbit.com/downloads/drbd/utils/archive/

```bash
      
tar xf drbd-utils-8.9.6.tar.gz 
cd drbd-utils-8.9.6
./configure --prefix=/usr/local/drbd-utils 
make && make install
# 加入开机自启
cp  /usr/local/drbd-utils/etc/rc.d/init.d/drbd /etc/rc.d/init.d/
chkconfig --add drbd
chkconfig drbd on
chkconfig --list | grep drbd
```

#### 修改配置文件

```bash
vim /usr/local/drbd-utils/etc/drbd.d/r0.res 
resource r0{  
        on mfs-master{  
                device          /dev/drbd1; #逻辑设备的路径  
                disk            /dev/sdb;  #物理设备  
                address         10.10.10.17:7788;  
                meta-disk       internal;  
        }  
        on mfs-slave{  
                device          /dev/drbd1;  
                disk            /dev/sdb;  
                address         10.10.10.18:7788;  
                meta-disk       internal;  
        }  
}  

# vim  /usr/local/drbd-utils/etc/drbd.d/global_common.conf



scp /usr/local/drbd-utils/etc/drbd.d/global_common.conf 10.10.10.17:/usr/local/drbd-utils/etc/drbd.d/global_common.conf
scp /usr/local/drbd-utils/etc/drbd.d/r0.res 10.10.10.17:/usr/local/drbd-utils/etc/drbd.d/r0.res
```

#### 格式化

```bash
格式化分区
mke2fs -t ext4 /dev/sdb
tune2fs -c -1 /dev/sdb1
用dd写入点数据，不然可能会出错
dd if=/dev/zero of=/dev/sdb bs=1M count=1
```



`以上步骤分别在两台机上操作`

#### 2.创建DRBD设备并激活r0资源：(master,slave)

```bash
#建立 drbd resource
drbdadm create-md r0  
service drbd start
```

#### **将drbd1主机配置为主节点：(master)**

```
#设为主服务器(mster)
drbdadm primary --force r0  
或者
drbdsetup /dev/drbd0 primary --force
```

#### 查看状态(master,slave)

```
service drbd status
或者
cat /proc/drbd
```



#### **挂载DRBD：(master)**

```
从刚才的状态上看到mounted和fstype参数为空，所以我们这步开始挂载DRBD到系统目录

mkfs.ext4 /dev/drbd1

mount /dev/drbd1 /data


```

`注：Secondary节点上不允许对DRBD设备进行任何操作，包括只读，所有的读写操作只能
在Primary节点上进行，只有当Primary节点挂掉时，Secondary节点才能提升为Primary节点继续工作。`

### 三、模拟故障

**(master)**

```
cd /data
touch 1 2 3 4 5
cd ..
umount /data
drbdsetup /dev/drbd1 secondary
```

`注：这里实际生产环境若DRBD1宕机，在DRBD2状态信息中ro的值会显示为Secondary/Unknown,只需要进行DRBD提权操作即可。`

#### **(Slave)**

```
drbdsetup /dev/drbd1 primary
mount  /dev/drbd1 /data
cd /data
touch 6 7 8 9 10
ls
--------------
1  10  2  3  4  5  6  7  8  9  lost+found
```



***

